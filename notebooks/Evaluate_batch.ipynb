{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c6929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始评估, 评估数据集长度为 60\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import  AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "\n",
    "url = \"http://localhost:4399/evaluate\"  # 如果是在不同机器上，替换为服务器IP\n",
    "\n",
    "def request_evaluate(query, content):\n",
    "    data = {\n",
    "        \"query\": query,\n",
    "        \"content\": content\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    try:\n",
    "        resoning = response.json()['reasoning']\n",
    "        ans = response.json()['ans']\n",
    "        score = response.json()['score']\n",
    "    except:\n",
    "        print(response.text)\n",
    "\n",
    "    return(resoning, ans, score)\n",
    "\n",
    "\n",
    "class chat_local_model():\n",
    "    def __init__(self, model_name, generate_cuda=\"cuda:0\"):\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # 原始FP16/FP32模型加载方式\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    def chat_transformers_model(self,content, system_content=\"你是一个有用的助手\"):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ]\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=1024\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return response\n",
    "    \n",
    "\n",
    "\n",
    "def chat_qwen(content, system_content = \"你是一个有用的助手!\", model_name = \"qwen2.5-14b-instruct\"):\n",
    "    #print(model_name)\n",
    "    client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=\"\", \n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    )\n",
    "    #time.sleep(1)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_name, # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_content},\n",
    "            {'role': 'user', 'content': content}],\n",
    "    )\n",
    "    \n",
    "    content = completion.choices[0].message.content\n",
    "    return content\n",
    "\n",
    "\n",
    "\n",
    "def chat_volces(content, syetem_content = \"你是一个有用的助手!\", model_name = \"doubao-1-5-lite-32k-250115\"):\n",
    "    url = 'https://ark.cn-beijing.volces.com/api/v3/chat/completions'\n",
    "    headers = {\n",
    "        'Authorization': \"\",\n",
    "        'Content-Type': 'application/json'  # 添加这个header确保服务器知道我们发送的是JSON数据。\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": syetem_content\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    ans = response.json()['choices'][0]['message']['content']\n",
    "    return(ans)\n",
    "\n",
    "def chat_deepseek(content, syetem_content = \"你是一个有用的助手!\", model_name = \"deepseek-chat\"):\n",
    "    client = OpenAI(api_key=\"\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": syetem_content},\n",
    "            {\"role\": \"user\", \"content\": content},\n",
    "        ],\n",
    "        stream=False  # 启用流式传输\n",
    "    )\n",
    "\n",
    "    return(response.choices[0].message.content)\n",
    "\n",
    "def chat_qianfan(content, system_content=\"你是一个有用的助手\", model_name=\"ernie-x1-32k-preview\"):\n",
    "    client = OpenAI(\n",
    "        base_url='https://qianfan.baidubce.com/v2',\n",
    "        api_key=''\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name, \n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_content\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content\n",
    "        }\n",
    "        ],\n",
    "        extra_body={ \n",
    "            \"web_search\":{\n",
    "        \"enable\": False,\n",
    "        \"enable_citation\": False,\n",
    "        \"enable_trace\": False\n",
    "        }\n",
    "        }\n",
    "    )\n",
    "    return (response.choices[0].message.content)\n",
    "\n",
    "def chat_xiaoai(content, system_content = \"你是一个有用的助手!\", model_name = \"gpt-3.5-turbo\"):\n",
    "    #print(model_name)\n",
    "    client = OpenAI(\n",
    "    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=\"\", \n",
    "    base_url=\"https://pro.xiaoai.plus/v1\",\n",
    "    )\n",
    "    #time.sleep(1)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_name, # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': system_content},\n",
    "            {'role': 'user', 'content': content}],\n",
    "    )\n",
    "    \n",
    "    content = completion.choices[0].message.content\n",
    "    return content\n",
    "\n",
    "def chat_dashscope(content, system_content=\"你是一个有用的助手\", model_name='llama3.3-70b-instruct'):\n",
    "    messages = [{'role': 'system', 'content': system_content},\n",
    "                {'role': 'user', 'content': content}]\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_delay = 3  # 初始延迟1秒\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = dashscope.Generation.call(\n",
    "                api_key=\"\",\n",
    "                model=model_name,\n",
    "                messages=messages,\n",
    "                result_format='message',\n",
    "            )\n",
    "            \n",
    "            if response.status_code == HTTPStatus.OK:\n",
    "                return response.output.choices[0].message.content\n",
    "            else:\n",
    "                raise Exception(f\"API request failed with status code: {response.status_code}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:  # 最后一次尝试也失败了\n",
    "                raise Exception(f\"Failed after {max_retries} attempts. Last error: {str(e)}\")\n",
    "            \n",
    "            print(f\"Attempt {attempt + 1} failed. Retrying in {retry_delay} seconds... Error: {str(e)}\")\n",
    "            time.sleep(retry_delay)\n",
    "            retry_delay *= 2  # 指数退避，每次延迟时间加倍\n",
    "\n",
    "def chat_qwen3(content, system_content=\"你是一个有用的助手\", model_name=\"qwen3-30b-a3b\"):\n",
    "    #print(f\"启动{model_name}\")\n",
    "        # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "    api_key=\"\"\n",
    "\n",
    "    client = OpenAI(\n",
    "        # 若没有配置环境变量，请用阿里云百炼API Key将下行替换为：api_key=\"sk-xxx\",\n",
    "        api_key=api_key,\n",
    "        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_name,  # 此处以qwen-plus为例，您可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": content}\n",
    "        ],\n",
    "        stream=True,\n",
    "        # Qwen3模型通过enable_thinking参数控制思考过程（开源版默认True，商业版默认False）\n",
    "        # 使用Qwen3开源版模型时，请将下行取消注释，否则会报错\n",
    "        extra_body={\"enable_thinking\": False},\n",
    "    )\n",
    "\n",
    "    full_content = \"\"\n",
    "    #print(\"流式输出内容为：\")\n",
    "    for chunk in completion:\n",
    "        # 如果stream_options.include_usage为True，则最后一个chunk的choices字段为空列表，需要跳过（可以通过chunk.usage获取 Token 使用量）\n",
    "        if chunk.choices:\n",
    "            full_content += chunk.choices[0].delta.content\n",
    "            #print(chunk.choices[0].delta.content)\n",
    "    return full_content\n",
    "\n",
    "def chat_manager(query, model_type, model_name, test_model):\n",
    "    if model_type == \"local_request\":\n",
    "        ans = test_model.chat_transformers_model(query)\n",
    "    elif model_type == \"qwen_api\":\n",
    "        ans = chat_qwen(query,model_name=model_name)\n",
    "    elif model_type == \"volces_api\":\n",
    "        ans = chat_volces(query, model_name=model_name)\n",
    "    elif model_type == \"deepseek_api\":\n",
    "        ans = chat_deepseek(query, model_name=model_name)\n",
    "    elif model_type == \"qianfan_api\":\n",
    "        ans = chat_qianfan(query, model_name=model_name)\n",
    "    elif model_type == \"xiaoai_api\":\n",
    "        ans = chat_xiaoai(query, model_name=model_name)\n",
    "    elif model_type == \"dashscope_api\":\n",
    "        ans = chat_dashscope(query, model_name=model_name)\n",
    "    elif model_type == \"qwen3_api\":\n",
    "        ans = chat_qwen3(query, model_name=model_name)\n",
    "    else:\n",
    "        print(f\"model_type error, {model_type}\")\n",
    "    return ans\n",
    "\n",
    "with open('../data/evaluate_data/random_sampled_query_evaluation_60.json', 'r') as f:\n",
    "    eval_data = json.load(f)\n",
    "#eval_data = eval_data_addition\n",
    "print(f\"开始评估, 评估数据集长度为 {len(eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107b452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始评估 Qwen2___5-0___5B-Instruct-GPTQ-Int4, 访问方式:local_request, 保存key_word: qwen_05B_int4\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2___5-0___5B-Instruct-GPTQ-Int8, 访问方式:local_request, 保存key_word: qwen_05B_int8\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2___5-0___5B-Instruct, 访问方式:local_request, 保存key_word: qwen_05B\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2___5-1___5B-Instruct, 访问方式:local_request, 保存key_word: qwen_15B\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2___5-3B-Instruct, 访问方式:local_request, 保存key_word: qwen_3B\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2___5-7B-Instruct, 访问方式:local_request, 保存key_word: qwen_7B\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2___5-7B-Instruct-GPTQ-Int4, 访问方式:local_request, 保存key_word: qwen_7B_int4\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2___5-7B-Instruct-GPTQ-Int8, 访问方式:local_request, 保存key_word: qwen_7B_int8\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2.5-Math-1.5B-Instruct, 访问方式:local_request, 保存key_word: qwen_math_15B\n",
      "数据已存在, 跳过\n",
      "开始评估 Qwen2.5-Math-7B-Instruct, 访问方式:local_request, 保存key_word: qwen_math_7B\n",
      "数据已存在, 跳过\n",
      "开始评估 MiniMind2-Small, 访问方式:local_request, 保存key_word: MiniMind2_small\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen2.5-14b-instruct, 访问方式:qwen_api, 保存key_word: qwen_14B\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen2.5-32b-instruct, 访问方式:qwen_api, 保存key_word: qwen_32B\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen2.5-72b-instruct, 访问方式:qwen_api, 保存key_word: qwen_72B\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen-max, 访问方式:qwen_api, 保存key_word: qwen-max\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen-plus, 访问方式:qwen_api, 保存key_word: qwen-plus\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen-turbo, 访问方式:qwen_api, 保存key_word: qwen-turbo\n",
      "数据已存在, 跳过\n",
      "开始评估 llama-4-scout-17b-16e-instruct, 访问方式:qwen_api, 保存key_word: llama4_scout_17B\n",
      "数据已存在, 跳过\n",
      "开始评估 llama-4-maverick-17b-128e-instruct, 访问方式:qwen_api, 保存key_word: llama4_maverick-17B\n",
      "数据已存在, 跳过\n",
      "开始评估 llama3.3-70b-instruct, 访问方式:qwen_api, 保存key_word: llama33_70B\n",
      "数据已存在, 跳过\n",
      "开始评估 deepseek-v3, 访问方式:qwen_api, 保存key_word: deepseek_v3\n",
      "数据已存在, 跳过\n",
      "开始评估 doubao-1-5-lite-32k-250115, 访问方式:volces_api, 保存key_word: volces_lite\n",
      "数据已存在, 跳过\n",
      "开始评估 doubao-1-5-pro-32k-250115, 访问方式:volces_api, 保存key_word: volces_pro\n",
      "数据已存在, 跳过\n",
      "开始评估 moonshot-v1-8k, 访问方式:volces_api, 保存key_word: kimi\n",
      "数据已存在, 跳过\n",
      "开始评估 moonshot-v1-32k, 访问方式:volces_api, 保存key_word: kimi_32k\n",
      "数据已存在, 跳过\n",
      "开始评估 moonshot-v1-128k, 访问方式:volces_api, 保存key_word: kimi_128k\n",
      "数据已存在, 跳过\n",
      "开始评估 deepseek-chat, 访问方式:deepseek_api, 保存key_word: deepseek_v3_0324\n",
      "数据已存在, 跳过\n",
      "开始评估 deepseek-reasoner, 访问方式:deepseek_api, 保存key_word: deepseek_r1\n",
      "数据已存在, 跳过\n",
      "开始评估 ernie-x1-32k-preview, 访问方式:qianfan_api, 保存key_word: ERNIE_X1\n",
      "数据已存在, 跳过\n",
      "开始评估 ernie-4.5-8k-preview, 访问方式:qianfan_api, 保存key_word: ERNIE_45\n",
      "数据已存在, 跳过\n",
      "开始评估 ernie-4.0-8k, 访问方式:qianfan_api, 保存key_word: ERNIE_40\n",
      "数据已存在, 跳过\n",
      "开始评估 ernie-speed-8k, 访问方式:qianfan_api, 保存key_word: ERNIE_speed\n",
      "数据已存在, 跳过\n",
      "开始评估 deepseek-r1-distill-qwen-1.5b, 访问方式:qianfan_api, 保存key_word: Qwen_ds_distill_15B\n",
      "数据已存在, 跳过\n",
      "开始评估 deepseek-r1-distill-qwen-7b, 访问方式:qianfan_api, 保存key_word: Qwen_ds_distill_7B\n",
      "数据已存在, 跳过\n",
      "开始评估 deepseek-r1-distill-qwen-14b, 访问方式:qianfan_api, 保存key_word: Qwen_ds_distill_14B\n",
      "数据已存在, 跳过\n",
      "开始评估 deepseek-r1-distill-qwen-32b, 访问方式:qianfan_api, 保存key_word: Qwen_ds_distill_32B\n",
      "数据已存在, 跳过\n",
      "开始评估 qwq-32b, 访问方式:qianfan_api, 保存key_word: Qwen_qwq_32B\n",
      "数据已存在, 跳过\n",
      "开始评估 gpt-3.5-turbo, 访问方式:xiaoai_api, 保存key_word: Chatgpt_35_turbo\n",
      "数据已存在, 跳过\n",
      "开始评估 gpt-4o, 访问方式:xiaoai_api, 保存key_word: Chatgpt_4o\n",
      "数据已存在, 跳过\n",
      "开始评估 llama3.2-1b-instruct, 访问方式:dashscope_api, 保存key_word: llama32_1B\n",
      "数据已存在, 跳过\n",
      "开始评估 llama3.2-3b-instruct, 访问方式:dashscope_api, 保存key_word: llama32_3B\n",
      "数据已存在, 跳过\n",
      "开始评估 farui-plus, 访问方式:dashscope_api, 保存key_word: Qwen_farui\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen3-0.6b, 访问方式:qwen3_api, 保存key_word: qwen3-0.6b\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen3-235b-a22b, 访问方式:qwen3_api, 保存key_word: qwen3-235b-a22b\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen3-32b, 访问方式:qwen3_api, 保存key_word: qwen3-32b\n",
      "数据已存在, 跳过\n",
      "开始评估 qwen3-30b-a3b, 访问方式:qwen3_api, 保存key_word: qwen3-30b-a3b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 20/60 [06:46<09:55, 14.89s/it]"
     ]
    }
   ],
   "source": [
    "def main_evaluation(key_word,model_type, model_path):\n",
    "    ## 测试结果保存目录\n",
    "    result_file_path =\"../data/result/generated_eval_data_test60.json\"\n",
    "    if isinstance(result_file_path):\n",
    "        with open(result_file_path, 'r') as f:\n",
    "            generate_eval_data_dict = json.load(f)\n",
    "\n",
    "    print(f\"开始评估 {model_path.split('/')[-1]}, 访问方式:{model_type}, 保存key_word: {key_word}\")\n",
    "    if key_word in generate_eval_data_dict:\n",
    "        #print(key_word,len(generate_eval_data_dict[key_word]['score']),len(eval_data))\n",
    "        if len(generate_eval_data_dict[key_word]['score']) == len(eval_data):\n",
    "        \n",
    "            print(\"数据已存在, 跳过\")\n",
    "            return None\n",
    "\n",
    "    if model_type == \"local_request\":\n",
    "        test_model = chat_local_model(model_path)\n",
    "    else:\n",
    "        test_model = None\n",
    "\n",
    "\n",
    "    reasoning_list = []\n",
    "    ans_list = []\n",
    "    score_list = []\n",
    "    content_list = []\n",
    "\n",
    "\n",
    "\n",
    "    for i in tqdm(range(len(eval_data))):\n",
    "        query = eval_data[i]['query']\n",
    "        content = chat_manager(query, model_type, model_name = model_path, test_model = test_model)\n",
    "        resoning, ans, score = request_evaluate(query,content)\n",
    "        reasoning_list.append(resoning)\n",
    "        ans_list.append(ans)\n",
    "        score_list.append(score)\n",
    "        content_list.append(content)\n",
    "    \n",
    "    if key_word not in generate_eval_data_dict:\n",
    "        generate_eval_data_dict[key_word] = {}\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(score_list, columns=[\"values\"])\n",
    "    summary = df.describe(percentiles=[0.25, 0.5, 0.75])  # 计算 25%、50%、75% 分位数\n",
    "    print(summary)\n",
    "    generate_eval_data_dict[key_word] = {\n",
    "        \"content\" : content_list,\n",
    "        \"reasoning\" : reasoning_list,\n",
    "        \"ans\" : ans_list,\n",
    "        \"score\" : score_list\n",
    "    }\n",
    "    with open(\"/data/home/shizeyang/lyh_workzone/LLM_Scores/V5/evaluation_data/generate_eval_data_test60.json\", 'w',encoding='utf-8') as f:\n",
    "        json.dump(generate_eval_data_dict, f, ensure_ascii=False, indent=4)\n",
    "    print(\"数据已保存!\")\n",
    "\n",
    "    if test_model is not None:\n",
    "        del test_model\n",
    "        print(\"已经清除模型缓存\")\n",
    "\n",
    "\n",
    "# 要测试的模型配置\n",
    "model_configs = [\n",
    "    (\"qwen_05B_int4\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-0___5B-Instruct-GPTQ-Int4\"),\n",
    "    (\"qwen_05B_int8\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-0___5B-Instruct-GPTQ-Int8\"),\n",
    "    (\"qwen_05B\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-0___5B-Instruct\"),\n",
    "    (\"qwen_15B\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-1___5B-Instruct\"),\n",
    "    (\"qwen_3B\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-3B-Instruct\"),\n",
    "    (\"qwen_7B\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-7B-Instruct\"),\n",
    "    (\"qwen_7B_int4\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-7B-Instruct-GPTQ-Int4\"),\n",
    "    (\"qwen_7B_int8\",\"local_request\", \"/data/home/shizeyang/shared/models/Qwen/Qwen2___5-7B-Instruct-GPTQ-Int8\"),\n",
    "    (\"qwen_math_15B\",\"local_request\", '/data/home/shizeyang/shared/models/Qwen/Qwen2.5-Math-1.5B-Instruct'),\n",
    "    (\"qwen_math_7B\",\"local_request\", '/data/home/shizeyang/shared/models/Qwen/Qwen2.5-Math-7B-Instruct'),\n",
    "    (\"MiniMind2_small\",\"local_request\", \"/data/home/shizeyang/shared/models/MiniMind2-Small\"),\n",
    "    (\"qwen_14B\",\"qwen_api\", \"qwen2.5-14b-instruct\"),\n",
    "    (\"qwen_32B\",\"qwen_api\", \"qwen2.5-32b-instruct\"),\n",
    "    (\"qwen_72B\",\"qwen_api\", \"qwen2.5-72b-instruct\"),\n",
    "    (\"qwen-max\",\"qwen_api\", \"qwen-max\"),\n",
    "    (\"qwen-plus\",\"qwen_api\", \"qwen-plus\"),\n",
    "    (\"qwen-turbo\",\"qwen_api\", \"qwen-turbo\"),\n",
    "    (\"llama4_scout_17B\",\"qwen_api\", \"llama-4-scout-17b-16e-instruct\"),\n",
    "    (\"llama4_maverick-17B\",\"qwen_api\", \"llama-4-maverick-17b-128e-instruct\"),\n",
    "    (\"llama33_70B\",\"qwen_api\", \"llama3.3-70b-instruct\"),\n",
    "    (\"deepseek_v3\",\"qwen_api\", \"deepseek-v3\"),\n",
    "    (\"volces_lite\",\"volces_api\", \"doubao-1-5-lite-32k-250115\"),\n",
    "    (\"volces_pro\",\"volces_api\", \"doubao-1-5-pro-32k-250115\"),\n",
    "    (\"kimi\",\"volces_api\", \"moonshot-v1-8k\"),\n",
    "    (\"kimi_32k\",\"volces_api\", \"moonshot-v1-32k\"),\n",
    "    (\"kimi_128k\",\"volces_api\", \"moonshot-v1-128k\"),\n",
    "    (\"deepseek_v3_0324\",\"deepseek_api\", \"deepseek-chat\"),\n",
    "    (\"deepseek_r1\",\"deepseek_api\", \"deepseek-reasoner\"),\n",
    "    (\"ERNIE_X1\",\"qianfan_api\", \"ernie-x1-32k-preview\"),\n",
    "    (\"ERNIE_45\",\"qianfan_api\", \"ernie-4.5-8k-preview\"),\n",
    "    (\"ERNIE_40\",\"qianfan_api\", \"ernie-4.0-8k\"),\n",
    "    (\"ERNIE_speed\",\"qianfan_api\", \"ernie-speed-8k\"),\n",
    "    (\"Qwen_ds_distill_15B\",\"qianfan_api\", \"deepseek-r1-distill-qwen-1.5b\"),\n",
    "    (\"Qwen_ds_distill_7B\",\"qianfan_api\", \"deepseek-r1-distill-qwen-7b\"),\n",
    "    (\"Qwen_ds_distill_14B\",\"qianfan_api\", \"deepseek-r1-distill-qwen-14b\"),\n",
    "    (\"Qwen_ds_distill_32B\",\"qianfan_api\", \"deepseek-r1-distill-qwen-32b\"),\n",
    "    (\"Qwen_qwq_32B\",\"qianfan_api\", \"qwq-32b\"),\n",
    "    (\"Chatgpt_35_turbo\",\"xiaoai_api\", \"gpt-3.5-turbo\"),\n",
    "    (\"Chatgpt_4o\",\"xiaoai_api\", \"gpt-4o\"),\n",
    "    (\"llama32_1B\",\"dashscope_api\", \"llama3.2-1b-instruct\"),\n",
    "    (\"llama32_3B\",\"dashscope_api\", \"llama3.2-3b-instruct\"),\n",
    "    (\"Qwen_farui\",\"dashscope_api\", \"farui-plus\"),\n",
    "    (\"qwen3-0.6b\",\"qwen3_api\",\"qwen3-0.6b\"),\n",
    "    (\"qwen3-235b-a22b\",\"qwen3_api\",\"qwen3-235b-a22b\"),\n",
    "    (\"qwen3-32b\",\"qwen3_api\",\"qwen3-32b\"),\n",
    "    (\"qwen3-30b-a3b\",\"qwen3_api\",\"qwen3-30b-a3b\"),\n",
    "    (\"qwen3-14b\",\"qwen3_api\",\"qwen3-14b\"),\n",
    "    (\"qwen3-4b\",\"qwen3_api\",\"qwen3-4b\"),\n",
    "    (\"qwen3-1.7b\",\"qwen3_api\",\"qwen3-1.7b\")\n",
    "]\n",
    "\n",
    "for config in model_configs:\n",
    "    key_word,model_type, model_path = config\n",
    "    model = main_evaluation(key_word,model_type, model_path)\n",
    "    #print(f\"已清理 {key_word} 模型的显存占用\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f372223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "独立测试集\n",
      "Model: qwen_05B, Score: 55.31 ± 12.43\n",
      "Model: qwen_15B, Score: 68.08 ± 11.15\n",
      "Model: qwen_3B, Score: 76.83 ± 7.15\n",
      "Model: qwen_7B, Score: 79.60 ± 7.60\n",
      "Model: qwen_14B, Score: 80.05 ± 7.01\n",
      "Model: qwen_32B, Score: 80.18 ± 8.05\n",
      "Model: qwen_72B, Score: 82.29 ± 6.73\n",
      "Model: volces_lite, Score: 84.84 ± 12.14\n",
      "Model: volces_pro, Score: 89.59 ± 5.73\n",
      "Model: deepseek_v3, Score: 87.27 ± 7.08\n",
      "Model: deepseek_v3_0324, Score: 94.09 ± 0.93\n",
      "Model: deepseek_r1, Score: 93.76 ± 1.23\n",
      "Model: qwen-max, Score: 84.65 ± 5.72\n",
      "Model: qwen-plus, Score: 89.78 ± 5.77\n",
      "Model: qwen-turbo, Score: 84.59 ± 10.04\n",
      "Model: llama4_scout_17B, Score: 75.32 ± 10.59\n",
      "Model: llama4_maverick-17B, Score: 75.77 ± 8.91\n",
      "Model: llama33_70B, Score: 69.80 ± 9.62\n",
      "Model: ERNIE_X1, Score: 92.95 ± 1.12\n",
      "Model: ERNIE_45, Score: 89.07 ± 4.99\n",
      "Model: ERNIE_40, Score: 74.07 ± 7.72\n",
      "Model: ERNIE_speed, Score: 70.10 ± 9.11\n",
      "Model: Qwen_ds_distill_15B, Score: 21.69 ± 11.73\n",
      "Model: Qwen_ds_distill_7B, Score: 53.43 ± 18.53\n",
      "Model: Qwen_ds_distill_14B, Score: 81.99 ± 12.98\n",
      "Model: Qwen_ds_distill_32B, Score: 85.51 ± 7.74\n",
      "Model: kimi, Score: 76.53 ± 8.55\n",
      "Model: qwen_math_15B, Score: 13.58 ± 12.99\n",
      "Model: qwen_math_7B, Score: 35.84 ± 17.41\n",
      "Model: Qwen_qwq_32B, Score: 94.06 ± 1.06\n",
      "Model: Chatgpt_35_turbo, Score: 66.11 ± 7.74\n",
      "Model: Chatgpt_4o, Score: 74.56 ± 7.75\n",
      "Model: kimi_32k, Score: 77.24 ± 7.92\n",
      "Model: MiniMind2_small, Score: 23.23 ± 12.55\n",
      "Model: kimi_128k, Score: 75.67 ± 6.94\n",
      "Model: qwen_05B_int4, Score: 45.81 ± 14.06\n",
      "Model: qwen_05B_int8, Score: 55.68 ± 11.64\n",
      "Model: qwen_7B_int4, Score: 77.56 ± 7.55\n",
      "Model: qwen_7B_int8, Score: 78.76 ± 7.84\n",
      "Model: Qwen_farui, Score: 79.12 ± 7.71\n",
      "Model: llama32_1B, Score: 43.44 ± 11.84\n",
      "Model: llama32_3B, Score: 57.38 ± 10.72\n",
      "Model: qwen3-0.6b, Score: 78.59 ± 14.49\n",
      "Model: qwen3-235b-a22b, Score: 93.38 ± 1.65\n",
      "Model: qwen3-32b, Score: 93.04 ± 1.48\n",
      "Model: qwen3-30b-a3b, Score: 92.87 ± 1.62\n",
      "Model: qwen3-14b, Score: 93.25 ± 1.17\n",
      "Model: qwen3-4b, Score: 92.61 ± 2.60\n",
      "Model: qwen3-1.7b, Score: 92.66 ± 2.06\n"
     ]
    }
   ],
   "source": [
    "with open(\"/data/home/shizeyang/lyh_workzone/LLM_Scores/V5/evaluation_data/generate_eval_data_test60.json\", 'r') as f:\n",
    "    generate_eval_data_dict = json.load(f)\n",
    "\n",
    "import numpy as np\n",
    "print(\"独立测试集\")\n",
    "for k, v in generate_eval_data_dict.items():\n",
    "    scores = v['score']\n",
    "    print(f\"Model: {k}, Score: {np.mean(scores):.2f} ± {np.std(scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b2dd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《刑法》第一百三十七条和第一百三十八条分别规定了“重大责任事故罪”和“重大劳动安全事故罪”。这两种犯罪在性质、主体、客体等方面有显著差异。\n",
      "\n",
      "### 一、性质\n",
      "\n",
      "1. **重大责任事故罪**：主要针对的是生产经营单位的管理人员，特别是负责安全生产管理工作的人员。\n",
      "2. **重大劳动安全事故罪**：主要针对的是直接从事生产、作业的劳动者（包括无雇工的个体工商户等）。\n",
      "\n",
      "### 二、主体\n",
      "\n",
      "1. **重大责任事故罪**：主体为一般主体，即任何自然人或法人组织均可构成。\n",
      "2. **重大劳动安全事故罪**：主体则为特殊主体，主要是指直接从事生产、作业的劳动者，主要包括从业人员。\n",
      "\n",
      "### 三、客体\n",
      "\n",
      "1. **重大责任事故罪**：侵犯的是公共安全的行为，具体表现为造成重大伤亡或者其他严重后果的情形。\n",
      "2. **重大劳动安全事故罪**：侵犯的是国家法律和社会秩序的行为，具体表现为造成重大伤亡或者对社会公私财产造成重大损失的情形。\n",
      "\n",
      "### 四、危害程度\n",
      "\n",
      "1. **重大责任事故罪**：其危害程度通常较轻，可能仅导致轻微的人身伤害或财产损失。\n",
      "2. **重大劳动安全事故罪**：其危害程度相对较大，可能导致严重的人员伤亡、经济损失甚至社会影响。\n",
      "\n",
      "### 共同点\n",
      "\n",
      "1. **均以危害公共安全为要件**：两罪都要求行为人违反了有关安全生产的规定，导致了人身伤亡或其他严重后果。\n",
      "2. **均需具备违法性**：两罪都需要行为人实施了违反法律法规的行为，但具体是否属于违法行为需要根据案件具体情况来判断。\n",
      "3. **均具有主观故意**：两罪都要求行为人明知自己的行为会危及公共安全，从而放任这种危险的发生。\n",
      "\n",
      "总的来说，《刑法》第一百三十七条和第一百三十八条虽然名称不同，但在性质、主体、客体以及危害程度上都有明显的区别，体现了法律对于保障人民生命财产安全的重要作用。\n"
     ]
    }
   ],
   "source": [
    "print(generate_eval_data_dict['qwen_05B']['content'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80cf3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
